setwd("C:/Users/chens/Desktop")     # file directory
work =read.csv("merged.csv",header=T,na.strings = "NA")     

### path analysis
library(RAMpath)
attach(work)        
m1 = '          # full model 
PHQ ~ adapt1
adapt1 ~ FMTC_LP + FMTC_PM
FMTC_LP ~ ZBI
FMTC_PM ~ ZBI
'
detach(work)

fit1 = sem(m1, data = work)
summary(fit1)
    
    # plot
library(semPlot)
semPaths(fit1)

### demographics
attach(work)
summary(ageR);summary(ageG);
cbind(table(genderR),prop.table(table(genderR)))
cbind(table(genderG),prop.table(table(genderG)))
cbind(table(Q37),prop.table(table(Q37)))    # marital - single, married, partner, widowed, separate, divorce
cbind(table(Q39),prop.table(table(Q39)))    # education - no, primary, secondary, vocational, college, graduate
cbind(table(Q42_1),prop.table(table(Q42_1)))    # economic burden - not at all, rarely, merely, mostly, completely

### correlations; 
library(GGally)
t = work[,c(303:305, 275, 311, 296)]  # LS, ZBI, FMTCs, adaptation, PHQ
rcor.test(t, method="pearson")
ggpairs(t)   


### model testing

m = (glm(PHQ ~ ageG+genderG+Q39+CGintensity+Q13+support+URCS_chg+RES+religion+work1, data=work, family=gaussian,na.action='na.omit')) 
m = (glm(PHQ ~ ageG+genderG+Q39+CGintensity+Q13+support+URCS_chg+RES+religion+work1, data=work, family=poisson,na.action='na.omit')) 
m = (glm(PHQ ~ ageG+genderG+Q39+CGintensity+Q13+support+URCS_chg+RES+religion, data=work, family=poisson,na.action='na.omit')) 

summary(glm(PHQ ~ ageG+Q39+CGintensity+Q13+support+URCS_chg+RES+religion, data=work, family=poisson,na.action='na.omit')) 



################################# 

install.packages("ltm")
install.packages("mirt")

library(ltm)
library(mirt)
library(semPLS); library(seminr); library(semPlot); library(lavaan)

setwd("C:/Users/chens/Desktop")
work =read.csv("merged.csv",header=T,na.strings = "NA")
# d = work[-c(58,73),]

# d1 = d[,c(140:150,187:205)]
# d2 = d[,c(159:163,164:167)]

w1 = work[which(work$generation==1),]
w2 = work[which(work$generation==2),]


t = work[,c(303:305, 275, 310, 296)]  # LS, ZBI, FMTCs, PACs,adapt_len
t1 = w1[, c(303:305, 275, 310, 296)]  # LS, ZBI, FMTCs, PACs,adapt_len
t2 = w2[, c(303:305, 275, 310, 296)]  # LS, ZBI, FMTCs, PACs,adapt_len

rcor.test(t, method="pearson")
rcor.test(t1, method="pearson")
rcor.test(t2, method="pearson")

ggpairs(t)   # library(GGally)
ggpairs(t1)   # library(GGally)
ggpairs(t2)   # library(GGally)

## path analysis

work$adapt = log(work$adapt_len)
work$a1 = log10(work$adapt_len)
hist(work$adapt_len)


work$p1 = log(work$PHQ+1, base = exp(1))

work$p1 = log(work$PHQ)
hist(work$p1)


prop.table(table(work$adapt))


library(epiDisplay)
tab1(work$adapt, sort.group = "decreasing", cum.percent = TRUE)
tab1(work$adapt, cum.percent = TRUE)
tab1(work$p1, cum.percent = TRUE)
tab1(work$p2, cum.percent = TRUE)


library(RAMpath)

attach(work)
m1 = '          # full model 
p1 ~ adapt1
adapt1 ~ FMTC_LP + FMTC_PM
FMTC_LP ~ ZBI
FMTC_PM ~ ZBI
'
m2 = '          # full model 
PHQ ~ adapt1
adapt1 ~ FMTC_LP + FMTC_PM
FMTC_LP ~ ZBI
FMTC_PM ~ ZBI
'
detach(work)



fit1 = sem(m1, data = work)
fit2 = sem(m2, data = work)
summary(fit1)
summary(fit2)


m1.0  = (glm(PHQ ~ adapt1, data=work, family=gaussian,na.action='na.omit')) 


### IRT

irt1 = mirt(data=d1, model=1, itemtype="gpcm")
irt2 = mirt(data=d2, model=1, itemtype="gpcm")

summary(irt1)
summary(irt2)

itemplot(irt1,1,type="trace")
itemplot(irt1,1,type="info")

itemplot(irt2,1,type="trace")
itemplot(irt2,1,type="info")

### SEM


m1 = "
ls =~ Q25_1+Q25_2+Q25_3+Q25_4+Q25_5
zbi =~ Q26_1+Q26_2+Q26_3+Q26_4
"

m2 = "
ls =~ Q25_1+Q25_2+Q25_3+Q25_4+Q25_5
zbi =~ Q26_1+Q26_2+Q26_3+Q26_4
global =~ ls + zbi
"

mb = "
ls =~ Q25_1+Q25_2+Q25_3+Q25_4+Q25_5
zbi =~ Q26_1+Q26_2+Q26_3+Q26_4
global =~ Q25_1+Q25_2+Q25_3+Q25_4+Q25_5+Q26_1+Q26_2+Q26_3+Q26_4
"


fit1 = cfa(m1,data=d)
fit2 = cfa(m2,data=d)
fit3 = cfa(mb,data=d, orthogonal=T,std.lv=T)


semPaths(fit1,whatLabels='std',layout='tree')
semPaths(fit2,whatLabels='std',layout='tree')
semPaths(fit3,whatLabels='std',layout='tree')

fitMeasures(fit1)
fitMeasures(fit2)
fitMeasures(fit3)

summary(fit1,standardized=T,rsquare=T)
summary(fit2,standardized=T,rsquare=T)
summary(fit3,standardized=T,rsquare=T)
 
### CFA
f2 = "
ls =~ Q25_1+Q25_2+Q25_3+Q25_4+Q25_5
zbi =~ Q26_1+Q26_2+Q26_3+Q26_4
"

f1 = "
f1 =~ Q25_1+Q25_2+Q25_3+Q25_4+Q25_5+Q26_1+Q26_2+Q26_3+Q26_4
"

fit2 = cfa(f2,data=d)
fit1 = cfa(f1,data=d)

semPaths(fit1,whatLabels='std',layout='tree')
semPaths(fit2,whatLabels='std',layout='tree')

summary(fit1,standardized=T,rsquare=T)
summary(fit2,standardized=T,rsquare=T)

## residual correlations
cor = residuals(fit2,type='cor')
zcor = residuals(fit2,type='standardized')
View(cor$cor)
View(zcor$cov)

## 

### GRM ###

out = grm(d1)
out2 = grm(d1, constrained=T)
anova(out,out2)

# compute margins
margins(out)
summary(out)
coef(out)

# plots
plot(out, lwd=2,type="ICC")
plot(out, lwd=2,type="OCCu")

# information
information(out,c(-10,10))
information(out,c(-10,10), items=10) # check specific items

#########################


data = work = read.csv("C:/Users/chens/OneDrive/research/Projects/1 Meaning Making - VL/GRF/analysis/merged.csv",header=T,na.strings = "NA")  

ggpairs(data, columns = 274:291)   # library(GGally)

aggregate(data$PAC, by=list(data$generation), FUN=mean)[2]